{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karnwatcharasupat/latte/blob/main/examples/morphomnist/morphomnist-keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SEjpqcL0FHh"
      },
      "source": [
        "# Using Latte with TensorFlow/Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4gm_C-N7MBz"
      },
      "source": [
        "This example notebook demonstrates the use of [Latte](https://github.com/karnwatcharasupat/latte) with [TensorFlow](https://tensorflow.org/). \n",
        "\n",
        "The code in this notebook is adapted from the [AR-VAE](https://github.com/ashispati/ar-vae) implementation:\n",
        "> A. Pati and A. Lerch, Attribute-based regularization of latent spaces for variational auto-encoders. Neural Computing & Applications, 33, 4429â€“4444 (2021). https://doi.org/10.1007/s00521-020-05270-2\n",
        "\n",
        "\n",
        "For this notebook, we will be using the [Morpho-MNIST](https://github.com/dccastro/Morpho-MNIST) dataset which is a disentanglement dataset built on the usual MNIST dataset.\n",
        "\n",
        "**Before you begin, please turn on GPU accelerator at `Runtime > Change runtime type > Hardware accelerator > GPU`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wmJgBAMfznu"
      },
      "outputs": [],
      "source": [
        "HOME = '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v4buxl60Lfv"
      },
      "source": [
        "## Installing Latte and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY1z4qYe0D5i"
      },
      "outputs": [],
      "source": [
        "# This command automatically install PyTorch and TorchMetrics.\n",
        "# For users with existing tensorflow>=2.0 installation, \n",
        "#   use `pip install latte-metrics` with no extras\n",
        "!pip install latte-metrics[keras] --upgrade\n",
        "\n",
        "!pip install tensorflow-probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbZfmlo18PXg"
      },
      "source": [
        "## Preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXx5z1SK1GCl"
      },
      "source": [
        "### Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nmis2eO1gIt"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "export DSET_PATH=\"/content/dataset\" \n",
        "mkdir -p $DSET_PATH\n",
        "gdown --id \"1fFGJW0IHoBmLuD6CEKCB8jz3Y5LJ5Duk\" -O $DSET_PATH/morphomnist.zip\n",
        "unzip -o \"$DSET_PATH/morphomnist.zip\" -d $DSET_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCGLIL6K5Bkq"
      },
      "source": [
        "### Cloning Morpho-MNIST measurement code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQSicjdF0b57"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dccastro/Morpho-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CweifwUB8JF_"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "sys.path.append(os.path.join(HOME, 'Morpho-MNIST'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGfmt5hR8JnF"
      },
      "source": [
        "### Creating dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eiisEft71kO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "from morphomnist import io, morpho\n",
        "\n",
        "class MorphoMnistDataset():\n",
        "\n",
        "    def __init__(self, root_dir=os.path.join(HOME, 'dataset/global')):\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.data_path_str = \"-images-idx3-ubyte.gz\"\n",
        "        self.label_path_str = \"-labels-idx1-ubyte.gz\"\n",
        "        self.morpho_path_str = \"-morpho.csv\"\n",
        "\n",
        "        self.train_dataset = self._create_dataset(dataset_type=\"train\")\n",
        "        self.val_dataset = self._create_dataset(dataset_type=\"t10k\")\n",
        "\n",
        "    def train_data(self, limit=None):\n",
        "        return self.train_dataset\n",
        "    \n",
        "    def val_data(self, limit=None):\n",
        "        return self.val_dataset\n",
        "\n",
        "    def _create_dataset(self, dataset_type):\n",
        "        data_path = os.path.join(\n",
        "            self.root_dir,\n",
        "            dataset_type + self.data_path_str\n",
        "        )\n",
        "        morpho_path = os.path.join(\n",
        "            self.root_dir,\n",
        "            dataset_type + self.morpho_path_str\n",
        "        )\n",
        "        images = io.load_idx(data_path)\n",
        "        images = np.expand_dims(images, axis=-1).astype('float32') / 255.0\n",
        "        morpho_labels = pd.read_csv(morpho_path).values.astype('float32')[:, 3:]\n",
        "        \n",
        "        \n",
        "        images = Dataset.from_tensor_slices(images)\n",
        "        morpho_labels = Dataset.from_tensor_slices(morpho_labels)\n",
        "        \n",
        "        dataset = Dataset.zip((images, morpho_labels))\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsHMwY__5TNa"
      },
      "source": [
        "## Creating a simple AR-VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjR3ICa2fzoJ"
      },
      "source": [
        "### Defining the Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI9EBkI-AqrT"
      },
      "outputs": [],
      "source": [
        "from tensorflow_probability import distributions\n",
        "\n",
        "def ar_signed_loss(z, a, factor=10.0):\n",
        "\n",
        "    n_attr = a.shape[-1]\n",
        "\n",
        "    # compute latent distance matrix\n",
        "    lc_dist_mat = z[:, None, :n_attr] - z[None, :, :n_attr]\n",
        "\n",
        "    # compute attribute distance matrix\n",
        "    attribute_dist_mat = a[:, None, ...] - a[None, :, :]\n",
        "\n",
        "    # compute regularization loss\n",
        "    lc_tanh = tf.tanh(lc_dist_mat * factor)\n",
        "    attribute_sign = tf.sign(attribute_dist_mat)\n",
        "    batch_size = z.shape[0]\n",
        "    ar_loss = tf.reduce_sum(tf.abs(lc_tanh - attribute_sign))/(batch_size ** 2 - batch_size)\n",
        "\n",
        "    return ar_loss\n",
        "\n",
        "def compute_loss(x, xhat, zd, z0, z, a, beta=1.0, gamma=1.0):\n",
        "\n",
        "    recon_loss = tf.reduce_sum(tf.math.squared_difference(x, tf.sigmoid(xhat)))/z.shape[0]\n",
        "\n",
        "    kld_loss = tf.reduce_mean(distributions.kl_divergence(zd, z0))\n",
        "\n",
        "    ar_loss = ar_signed_loss(z, a)\n",
        "\n",
        "    return {\n",
        "        'loss': recon_loss + beta * kld_loss + gamma * ar_loss,\n",
        "        'recon_loss': recon_loss,\n",
        "        'kld_loss': kld_loss,\n",
        "        'ar_loss': ar_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGdZimrAfzoN"
      },
      "source": [
        "### Defining base VAE class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alAggbUd5VBk"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "\n",
        "class ImageVAE(tfk.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_size = 784\n",
        "        self.z_dim = 16\n",
        "        self.inter_dim = 19\n",
        "        self.enc_conv = tfk.Sequential([\n",
        "            tfkl.Conv2D(64, 4, 1, activation='selu'),\n",
        "            tfkl.Dropout(0.5),\n",
        "            tfkl.Conv2D(64, 4, 1, activation='selu'),\n",
        "            tfkl.Dropout(0.5),\n",
        "            tfkl.Conv2D(8, 4, 1, activation='selu'),\n",
        "            tfkl.Dropout(0.5),\n",
        "        ])\n",
        "        self.enc_lin = tfkl.Dense(256, activation='selu')\n",
        "        self.enc_mean = tfkl.Dense(self.z_dim)\n",
        "        self.enc_log_std = tfkl.Dense(self.z_dim)\n",
        "        self.dec_lin = tfk.Sequential([\n",
        "            tfkl.Dense(256, activation='selu'),\n",
        "            tfkl.Dense(2888, activation='selu')\n",
        "        ])\n",
        "        self.dec_conv = tfk.Sequential([\n",
        "            tfkl.Conv2DTranspose(64, 4, 1, activation='selu'),\n",
        "            tfkl.Dropout(0.5),\n",
        "            tfkl.Conv2DTranspose(64, 4, 1, activation='selu'),\n",
        "            tfkl.Dropout(0.5),\n",
        "            tfkl.Conv2DTranspose(1, 4, 1, activation='selu'),\n",
        "        ])\n",
        "\n",
        "    @tf.function\n",
        "    def encode(self, x):\n",
        "        hidden = self.enc_conv(x)\n",
        "        hidden = tf.reshape(hidden, (hidden.shape[0], -1))\n",
        "        hidden = self.enc_lin(hidden)\n",
        "        z_mean = self.enc_mean(hidden)\n",
        "        z_log_std = self.enc_log_std(hidden)\n",
        "        z_distribution = distributions.Normal(loc=z_mean, scale=tf.exp(z_log_std) + 1e-16)\n",
        "        return z_distribution\n",
        "\n",
        "    @tf.function\n",
        "    def decode(self, z):\n",
        "        hidden = self.dec_lin(z)\n",
        "        hidden = tf.reshape(hidden, (z.shape[0], self.inter_dim, self.inter_dim, -1))\n",
        "        hidden = self.dec_conv(hidden)\n",
        "        return hidden\n",
        "\n",
        "    @tf.function\n",
        "    def reparametrize(self, z_dist):\n",
        "        # sample from distribution\n",
        "        z_tilde = z_dist.sample()\n",
        "\n",
        "        # compute prior\n",
        "        prior_dist = distributions.Normal(\n",
        "            loc=tf.zeros_like(z_dist.loc),\n",
        "            scale=tf.ones_like(z_dist.scale)\n",
        "        )\n",
        "        return z_tilde, prior_dist\n",
        "    \n",
        "    @tf.function\n",
        "    def interpolate(self, x, dz):\n",
        "        \n",
        "        # compute distribution using encoder\n",
        "        z_dist = self.encode(x)\n",
        "\n",
        "        # reparametrize\n",
        "        z_tilde, prior_dist = self.reparametrize(z_dist)\n",
        "\n",
        "        # compute output of decoding layer\n",
        "        if len(dz.shape) > 1:\n",
        "            output = []\n",
        "            for i in range(dz.shape[-1]):\n",
        "                output.append(tf.reshape(self.decode(z_tilde + dz[None, :, i]), x.shape))\n",
        "            output = tf.stack(output, axis=-1)\n",
        "        else:\n",
        "            output = tf.reshape(self.decode(z_tilde + dz[None, :]), x.shape)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06zCqD-3fzoR"
      },
      "source": [
        "### Add custom training to the model\n",
        "\n",
        "See Latte documentation [here](https://latte.readthedocs.io/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3xgEYAHfzoR"
      },
      "outputs": [],
      "source": [
        "from latte.metrics.keras.bundles import DependencyAwareMutualInformationBundle\n",
        "\n",
        "class ImageVAEwithLatte(ImageVAE):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.dami = DependencyAwareMutualInformationBundle(reg_dim=range(4))\n",
        "        \n",
        "    def call(self, x):\n",
        "        # compute distribution using encoder\n",
        "        z_dist = self.encode(x)\n",
        "\n",
        "        # reparametrize\n",
        "        z_tilde, prior_dist = self.reparametrize(z_dist)\n",
        "\n",
        "        # compute output of decoding layer\n",
        "        output = tf.reshape(self.decode(z_tilde), x.shape)\n",
        "\n",
        "        return output, z_dist, prior_dist, z_tilde\n",
        "    \n",
        "    def train_step(self, data):\n",
        "        x, a = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            output, z_dist, prior_dist, z_tilde = self(x, training=True)\n",
        "            loss = compute_loss(x, output, z_dist, prior_dist, z_tilde, a)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss['loss'], trainable_vars)\n",
        "        \n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        \n",
        "        # Compute train metrics every 8 batch\n",
        "        if len(self.dami.z) == 8:\n",
        "          self.dami.update_state(z_tilde, a)\n",
        "          metrics = self.dami.result()\n",
        "          self.dami.reset_state()\n",
        "          return {**loss, **metrics}\n",
        "        else:\n",
        "          return loss\n",
        "    \n",
        "    def test_step(self, data):\n",
        "        x, a = data\n",
        "        output, z_dist, prior_dist, z_tilde = self(x, training=True)\n",
        "        loss = compute_loss(x, output, z_dist, prior_dist, z_tilde, a)\n",
        "        \n",
        "        # use all validation data for validation metric computation\n",
        "        self.dami.update_state(z_tilde, a)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_state()` yourself at the time of your choosing.\n",
        "        return [self.dami]\n",
        "    \n",
        "class ValidationMetricsCallback(tfk.callbacks.Callback):\n",
        "    def on_test_end(self, logs=None):\n",
        "        val_metrics = self.model.dami.result()\n",
        "        \n",
        "        print(\"\\nValidation metrics: \")\n",
        "        for k in val_metrics:\n",
        "            print(f\"{k}: \", val_metrics[k].numpy().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6803GEY-RQJE"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "For your convenience, we have prepared pretrained weights for the model. This notebook will only train for one more epoch as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gJDOpR7fzoT"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/karnwatcharasupat/latte/raw/main/examples/morphomnist/weights/morphomnist-tf-weights.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hvsM1wP6lqk"
      },
      "outputs": [],
      "source": [
        "import latte\n",
        "\n",
        "latte.seed(42) \n",
        "# there is no need for this\n",
        "# this is just to demonstrate that you can manually set a seed\n",
        "# Latte uses seed=42 by default anyway\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = ImageVAEwithLatte()\n",
        "\n",
        "dataset = MorphoMnistDataset()\n",
        "train_data = dataset.train_data().take(6000).shuffle(6000).batch(32, drop_remainder=True)\n",
        "val_data = dataset.val_data().take(1000).batch(32, drop_remainder=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tfk.optimizers.Adam(learning_rate=1e-4),\n",
        "    run_eagerly=True, # to evaluate latte metrics mid-training, eager mode is currently required\n",
        ")\n",
        "\n",
        "model.build((32, 28, 28, 1))\n",
        "model.load_weights(os.path.join(HOME, 'morphomnist-tf-weights.h5'))\n",
        "\n",
        "model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=1,\n",
        "    callbacks=[ValidationMetricsCallback()]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dadw8FNJfzoV"
      },
      "source": [
        "## Visualizing the outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n0XBhCrfzoW"
      },
      "outputs": [],
      "source": [
        "atttribute_dict = {\n",
        "    \"thickness\": 0,\n",
        "    \"slant\": 1,\n",
        "    \"width\": 2,\n",
        "    \"height\": 3\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExWpiPr_fzoX"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "def interpolate_and_display(model, attribute):\n",
        "    f = plt.figure(figsize=(16, 16))\n",
        "    ax = ImageGrid(\n",
        "        f, 111,  # similar to subplot(111)\n",
        "        nrows_ncols=(11, 8),  # creates 2x2 grid of axes\n",
        "        axes_pad=0.1,  # pad between axes in inch.\n",
        "    )\n",
        "\n",
        "    inputs = dataset.val_data().map(lambda x, a: x).batch(8).take(1).get_single_element()\n",
        "    \n",
        "    dz = np.zeros((16, 10), dtype=np.float32)\n",
        "    dz[atttribute_dict[attribute], :] = np.linspace(-2.0, 2.0, 10)\n",
        "    dz = tf.convert_to_tensor(dz)\n",
        "\n",
        "    gen = model.interpolate(inputs, dz)\n",
        "    gen = tf.sigmoid(gen)\n",
        "\n",
        "    for i in range(8):\n",
        "        ax[i].imshow(inputs[i, :, :, 0], cmap='summer')\n",
        "        for j in range(10):\n",
        "            ax[(j+1)*8+i].imshow(gen[i, :, :, 0, j], cmap='gray', vmin=0, vmax=1)\n",
        "    \n",
        "    for i in range(8*11):\n",
        "        ax[i].axis('off')\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ1L4OiNfzoZ"
      },
      "outputs": [],
      "source": [
        "interpolate_and_display(model, 'thickness')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_v4T2t4fzob"
      },
      "outputs": [],
      "source": [
        "interpolate_and_display(model, 'slant')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de1aAmoafzob"
      },
      "outputs": [],
      "source": [
        "interpolate_and_display(model, 'width')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist-lightning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}