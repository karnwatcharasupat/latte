{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karnwatcharasupat/latte/blob/issues%2F17-examples/examples/mnist-torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Latte with Pytorch Lightning"
      ],
      "metadata": {
        "id": "0SEjpqcL0FHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you begin, please turn on GPU accelerator at `Runtime > Change runtime type > Hardware accelerator > GPU`.\n"
      ],
      "metadata": {
        "id": "P4gm_C-N7MBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Latte and Dependencies"
      ],
      "metadata": {
        "id": "8v4buxl60Lfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This command automatically install PyTorch and TorchMetrics.\n",
        "# For users with existing pytorch>=1.3.1 and torchmetrics>=0.2.0 installation, \n",
        "#   use `pip install latte-metrics` with no extras\n",
        "!pip install -q latte-metrics[pytorch]  \n",
        "\n",
        "# Pytorch Lightning is installed independently\n",
        "!pip install -q pytorch-lightning       "
      ],
      "metadata": {
        "id": "iY1z4qYe0D5i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing data"
      ],
      "metadata": {
        "id": "jbZfmlo18PXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading dataset"
      ],
      "metadata": {
        "id": "VXx5z1SK1GCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/dataset\n",
        "!gdown --id \"1fFGJW0IHoBmLuD6CEKCB8jz3Y5LJ5Duk\" -O /content/dataset/morphomnist.zip\n",
        "!unzip -o \"/content/dataset/morphomnist.zip\" -d /content/dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nmis2eO1gIt",
        "outputId": "bd92a03d-ad63-4099-ec62-65c25a760b11"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fFGJW0IHoBmLuD6CEKCB8jz3Y5LJ5Duk\n",
            "To: /content/dataset/morphomnist.zip\n",
            "\r  0% 0.00/15.5M [00:00<?, ?B/s]\r100% 15.5M/15.5M [00:00<00:00, 137MB/s]\n",
            "Archive:  /content/dataset/morphomnist.zip\n",
            " extracting: /content/dataset/global/train-pert-idx1-ubyte.gz  \n",
            "  inflating: /content/dataset/global/train-images-idx3-ubyte.gz  \n",
            "  inflating: /content/dataset/global/train-morpho.csv  \n",
            " extracting: /content/dataset/global/train-labels-idx1-ubyte.gz  \n",
            " extracting: /content/dataset/global/t10k-pert-idx1-ubyte.gz  \n",
            "  inflating: /content/dataset/global/t10k-images-idx3-ubyte.gz  \n",
            "  inflating: /content/dataset/global/t10k-morpho.csv  \n",
            " extracting: /content/dataset/global/t10k-labels-idx1-ubyte.gz  \n",
            "  inflating: /content/dataset/global/README-global.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning Morpho-MNIST measurement code"
      ],
      "metadata": {
        "id": "HCGLIL6K5Bkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dccastro/Morpho-MNIST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQSicjdF0b57",
        "outputId": "f52f2c57-2bd4-4134-ef71-11f50378187e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Morpho-MNIST' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Morpho-MNIST')"
      ],
      "metadata": {
        "id": "CweifwUB8JF_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating dataloader"
      ],
      "metadata": {
        "id": "sGfmt5hR8JnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from morphomnist import io, morpho\n",
        "\n",
        "class MorphoMnistDataset():\n",
        "\n",
        "    def __init__(self, root_dir='/content/dataset/global'):\n",
        "        super().__init__()\n",
        "        self.kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "        self.root_dir = root_dir\n",
        "        self.data_path_str = \"-images-idx3-ubyte.gz\"\n",
        "        self.label_path_str = \"-labels-idx1-ubyte.gz\"\n",
        "        self.morpho_path_str = \"-morpho.csv\"\n",
        "\n",
        "        self.train_dataset = self._create_dataset(dataset_type=\"train\")\n",
        "        self.val_dataset = self._create_dataset(dataset_type=\"t10k\")\n",
        "\n",
        "    def data_loaders(self, batch_size):\n",
        "        train_dl = DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            **self.kwargs\n",
        "        )\n",
        "        val_dl = DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "        )\n",
        "        return train_dl, val_dl\n",
        "\n",
        "    def _create_dataset(self, dataset_type=\"train\"):\n",
        "        data_path = os.path.join(\n",
        "            self.root_dir,\n",
        "            dataset_type + self.data_path_str\n",
        "        )\n",
        "        morpho_path = os.path.join(\n",
        "            self.root_dir,\n",
        "            dataset_type + self.morpho_path_str\n",
        "        )\n",
        "        images = io.load_idx(data_path)\n",
        "        images = np.expand_dims(images, axis=1).astype('float32') / 255.0\n",
        "        morpho_labels = pd.read_csv(morpho_path).values.astype('float32')\n",
        "        dataset = TensorDataset(\n",
        "            torch.from_numpy(images),\n",
        "            torch.from_numpy(morpho_labels)\n",
        "        )\n",
        "        return dataset"
      ],
      "metadata": {
        "id": "_eiisEft71kO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a simple VAE\n",
        "\n",
        "Using the model from\n",
        "> A. Pati and A. Lerch, Attribute-based regularization of latent spaces for variational auto-encoders. Neural Computing & Applications, 33, 4429–4444 (2021). https://doi.org/10.1007/s00521-020-05270-2\n",
        "\n"
      ],
      "metadata": {
        "id": "FsHMwY__5TNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, distributions\n",
        "\n",
        "class ImageVAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_size = 784\n",
        "        self.z_dim = 16\n",
        "        self.inter_dim = 19\n",
        "        self.enc_conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(64, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(64, 8, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "        self.enc_lin = nn.Sequential(\n",
        "            nn.Linear(2888, 256),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.enc_mean = nn.Linear(256, self.z_dim)\n",
        "        self.enc_log_std = nn.Linear(256, self.z_dim)\n",
        "        self.dec_lin = nn.Sequential(\n",
        "            nn.Linear(self.z_dim, 256),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(256, 2888),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.dec_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(8, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ConvTranspose2d(64, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ConvTranspose2d(64, 1, 4, 1),\n",
        "        )\n",
        "\n",
        "        self.xavier_initialization()\n",
        "\n",
        "    def xavier_initialization(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "\n",
        "    def encode(self, x):\n",
        "        hidden = self.enc_conv(x)\n",
        "        hidden = hidden.view(x.size(0), -1)\n",
        "        hidden = self.enc_lin(hidden)\n",
        "        z_mean = self.enc_mean(hidden)\n",
        "        z_log_std = self.enc_log_std(hidden)\n",
        "        z_distribution = distributions.Normal(loc=z_mean, scale=torch.exp(z_log_std) + 1e-16)\n",
        "        return z_distribution\n",
        "\n",
        "    def decode(self, z):\n",
        "        hidden = self.dec_lin(z)\n",
        "        hidden = hidden.view(z.size(0), -1, self.inter_dim, self.inter_dim)\n",
        "        hidden = self.dec_conv(hidden)\n",
        "        return hidden\n",
        "\n",
        "    def reparametrize(self, z_dist):\n",
        "        # sample from distribution\n",
        "        z_tilde = z_dist.rsample()\n",
        "\n",
        "        # compute prior\n",
        "        prior_dist = torch.distributions.Normal(\n",
        "            loc=torch.zeros_like(z_dist.loc),\n",
        "            scale=torch.ones_like(z_dist.scale)\n",
        "        )\n",
        "        return z_tilde, prior_dist\n",
        "\n",
        "    def forward(self, x):\n",
        "        # compute distribution using encoder\n",
        "        z_dist = self.encode(x)\n",
        "\n",
        "        # reparametrize\n",
        "        z_tilde, prior_dist = self.reparametrize(z_dist)\n",
        "\n",
        "        # compute output of decoding layer\n",
        "        output = self.decode(z_tilde).view(x.size())\n",
        "\n",
        "        return output, z_dist, prior_dist, z_tilde"
      ],
      "metadata": {
        "id": "alAggbUd5VBk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Loss Function"
      ],
      "metadata": {
        "id": "8K237NXYRLUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "def ar_signed_loss(z, a, factor=10.0):\n",
        "\n",
        "    n_attr = a.shape[-1]\n",
        "\n",
        "    # compute latent distance matrix\n",
        "    lc_dist_mat = z[:, None, :n_attr] - z[None, :, :n_attr]\n",
        "\n",
        "    # compute attribute distance matrix\n",
        "    attribute_dist_mat = a[:, None, ...] - a[None, :, :]\n",
        "\n",
        "    # compute regularization loss\n",
        "    lc_tanh = torch.tanh(lc_dist_mat * factor)\n",
        "    attribute_sign = torch.sign(attribute_dist_mat)\n",
        "    ar_loss = F.l1_loss(lc_tanh, attribute_sign.float(), reduction='sum')/z.shape[0]\n",
        "\n",
        "    return ar_loss\n",
        "\n",
        "def compute_loss(x, xhat, zd, z0, z, a):\n",
        "\n",
        "    recon_loss = F.mse_loss(x, torch.sigmoid(xhat), reduction='sum')/z.shape[0]\n",
        "\n",
        "    kld_loss = distributions.kl.kl_divergence(zd, z0).sum(-1).mean()\n",
        "\n",
        "    ar_loss = ar_signed_loss(z, a)\n",
        "\n",
        "    return recon_loss + kld_loss + ar_loss"
      ],
      "metadata": {
        "id": "sI9EBkI-AqrT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model, Optimizer, and Metrics"
      ],
      "metadata": {
        "id": "6803GEY-RQJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "lr = 1e-4"
      ],
      "metadata": {
        "id": "EmFWphNO9wU1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import latte\n",
        "from latte.metrics.torch.bundles import DependencyAwareMutualInformationBundle\n",
        "\n",
        "latte.seed(42) \n",
        "# there is no need for this\n",
        "# this is just to demonstrate that you can manually set a seed\n",
        "# Latte uses seed=42 by default anyway\n",
        "\n",
        "train_dl, val_dl =  MorphoMnistDataset().data_loaders(batch_size)\n",
        "\n",
        "model = ImageVAE().cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "dami = DependencyAwareMutualInformationBundle(reg_dim=range(7))"
      ],
      "metadata": {
        "id": "8hvsM1wP6lqk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Docstring for `DependencyAwareMutualInformationBundle`\n",
        "\n",
        "    Calculate between latent vectors and attributes:\n",
        "        - Mutual Information Gap (MIG) \n",
        "        - Dependency-Aware Mutual Information Gap (DMIG) \n",
        "        - Dependency-Blind Mutual Information Gap (XMIG) \n",
        "        - Dependency-Aware Latent Information Gap (DLIG) \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    reg_dim : Optional[List], optional\n",
        "        regularized dimensions, by default None\n",
        "        Attribute `a[:, i]` is regularized by `z[:, reg_dim[i]]`. If `None`, `a[:, i]` is assumed to be regularized by `z[:, i]`.\n",
        "    discrete : bool, optional\n",
        "        Whether the attributes are discrete, by default False\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, np.ndarray]\n",
        "        A dictionary of mutual information metrics with keys ['MIG', 'DMIG', 'XMIG', 'DLIG'] each mapping to a corresponding metric np.ndarray of shape (n_attributes,).\n",
        "    \n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Q. Chen, X. Li, R. Grosse, and D. Duvenaud, “Isolating sources of disentanglement in variational autoencoders”, in Proceedings of the 32nd International Conference on Neural Information Processing Systems, 2018.\n",
        "    .. [2] K. N. Watcharasupat and A. Lerch, “Evaluation of Latent Space Disentanglement in the Presence of Interdependent Attributes”, in Extended Abstracts of the Late-Breaking Demo Session of the 22nd International Society for Music Information Retrieval Conference, 2021.\n",
        "    .. [3] K. N. Watcharasupat, “Controllable Music: Supervised Learning of Disentangled Representations for Music Generation”, 2021."
      ],
      "metadata": {
        "id": "qiJvf36dUXH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "XOe8XU3b8pA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "n_batch = len(train_dl)\n",
        "\n",
        "postfix = {}\n",
        "\n",
        "\n",
        "for epoch_index in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    with tqdm(total=n_batch) as prog_bar:\n",
        "        prog_bar.set_description(f\"epoch {epoch_index+1}/{num_epochs}\")\n",
        "\n",
        "        for i, data in enumerate(train_dl):\n",
        "            prog_bar.update()\n",
        "            \n",
        "            inputs, attributes = data\n",
        "            inputs = inputs.cuda()\n",
        "            attributes = attributes.cuda()\n",
        "\n",
        "            recon, z_dist, prior_dist, z_tilde = model(inputs)\n",
        "            \n",
        "            model.zero_grad()\n",
        "\n",
        "            loss = compute_loss(\n",
        "                inputs, recon, z_dist, prior_dist, z_tilde, attributes\n",
        "            )\n",
        "\n",
        "            postfix.update({\"train/loss\": f\"{loss.detach().cpu().numpy():3.2g}\"})\n",
        "            \n",
        "            # compute train MIG using information the last batch of the train set in each epoch\n",
        "            # the return values are converted back to torch dtype automatically\n",
        "            if i == n_batch - 1:\n",
        "\n",
        "                # Latte automatically move all data to CPU\n",
        "                # There is no need to call `.cpu()` here.\n",
        "                dami.update(z_tilde, attributes)\n",
        "\n",
        "                train_metrics = dami.compute()\n",
        "                \n",
        "                # Morpho-MNIST has 7 attributes. \n",
        "                # Each metric in `dami_train` has shape (7,) \n",
        "                #   with each element representing the MIG for each attribute.\n",
        "                # We only put the mean metrics over the attributes here on the progress bar for demonstration\n",
        "                postfix.update({f\"train/{k}\": f\"{train_metrics[k].numpy().mean():.3g}\" for k in train_metrics})\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            prog_bar.set_postfix(postfix)\n",
        "\n",
        "        # reset cache for validation loop\n",
        "        dami.reset()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "\n",
        "        for data in val_dl:\n",
        "\n",
        "            inputs, attributes = data\n",
        "            inputs = inputs.cuda()\n",
        "            attributes = attributes.cuda()\n",
        "\n",
        "            recon, z_dist, prior_dist, z_tilde = model(inputs)\n",
        "\n",
        "            loss = compute_loss(\n",
        "                inputs, recon, z_dist, prior_dist, z_tilde, attributes\n",
        "            )\n",
        "\n",
        "            val_loss += loss\n",
        "\n",
        "            # use the entire validation set to compute metrics this time\n",
        "            dami.update(z_tilde, attributes)\n",
        "\n",
        "        # only compute once at the end of the validation loop \n",
        "        # using all validation batches\n",
        "        val_metrics = dami.compute()\n",
        "\n",
        "        print(f\"Epoch {epoch_index+1}/{num_epochs}\")\n",
        "        print(f\"Validation loss: {val_loss/len(val_dl):3.2g}\")\n",
        "        for metric in val_metrics:\n",
        "            print(f\"Validation {metric}:\\t{val_metrics[metric].numpy().mean():.3g}\")\n",
        "\n",
        "        # reset cache for the next train loop\n",
        "        dami.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6a399fb992244e4f95632df22228db02",
            "26be1cc09bba403491747d0a20140373",
            "5970bb50ff844ec7acfd02ff68db8010",
            "47c1be5335ad4f1e97b81dddda3a9d79",
            "84c042f3ceca4495be006145d97c81cf",
            "2fa0e4d346ea48c3a520ca8d9e014703",
            "7fe4080d475a41319b3ea064267ab37b",
            "6a2a135150974910b197f7b5d501a0f4",
            "53ad6097a36c4f168993fa7e7c9c0256",
            "42e75f19949c48b1b0fd5ef711481334",
            "9f85f8eec6ae4419873149fe830fa6a4"
          ]
        },
        "id": "mblhS28n97z_",
        "outputId": "156dc6e5-b728-4933-edff-11f00f8bb6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a399fb992244e4f95632df22228db02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1875 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6fl_eFSfU8PG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "mnist-lightning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a399fb992244e4f95632df22228db02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26be1cc09bba403491747d0a20140373",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5970bb50ff844ec7acfd02ff68db8010",
              "IPY_MODEL_47c1be5335ad4f1e97b81dddda3a9d79",
              "IPY_MODEL_84c042f3ceca4495be006145d97c81cf"
            ]
          }
        },
        "26be1cc09bba403491747d0a20140373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5970bb50ff844ec7acfd02ff68db8010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2fa0e4d346ea48c3a520ca8d9e014703",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "epoch 1/10:  57%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fe4080d475a41319b3ea064267ab37b"
          }
        },
        "47c1be5335ad4f1e97b81dddda3a9d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a2a135150974910b197f7b5d501a0f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1875,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1067,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53ad6097a36c4f168993fa7e7c9c0256"
          }
        },
        "84c042f3ceca4495be006145d97c81cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42e75f19949c48b1b0fd5ef711481334",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1067/1875 [00:23&lt;00:17, 47.08it/s, train/loss=1.9e+02]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f85f8eec6ae4419873149fe830fa6a4"
          }
        },
        "2fa0e4d346ea48c3a520ca8d9e014703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fe4080d475a41319b3ea064267ab37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a2a135150974910b197f7b5d501a0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53ad6097a36c4f168993fa7e7c9c0256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42e75f19949c48b1b0fd5ef711481334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f85f8eec6ae4419873149fe830fa6a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}