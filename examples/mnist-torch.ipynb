{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karnwatcharasupat/latte/blob/issues%2F17-examples/examples/mnist-torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Notebook for using Latte with Pytorch Lightning"
      ],
      "metadata": {
        "id": "0SEjpqcL0FHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "rVHuiLkx5JyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Latte and Dependencies"
      ],
      "metadata": {
        "id": "8v4buxl60Lfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This command automatically install PyTorch and TorchMetrics.\n",
        "# For users with existing pytorch>=1.3.1 and torchmetrics>=0.2.0 installation, \n",
        "#   use `pip install latte-metrics` with no extras\n",
        "!pip install -q latte-metrics[pytorch]  \n",
        "\n",
        "# Pytorch Lightning is installed independently\n",
        "!pip install -q pytorch-lightning       "
      ],
      "metadata": {
        "id": "iY1z4qYe0D5i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading dataset"
      ],
      "metadata": {
        "id": "VXx5z1SK1GCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/dataset\n",
        "!gdown --id \"1fFGJW0IHoBmLuD6CEKCB8jz3Y5LJ5Duk\" -O /content/dataset/morphomnist.zip\n",
        "!unzip \"/content/dataset/morphomnist.zip\" -d /content/dataset/"
      ],
      "metadata": {
        "id": "-nmis2eO1gIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning Morpho-MNIST measurement code"
      ],
      "metadata": {
        "id": "HCGLIL6K5Bkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dccastro/Morpho-MNIST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQSicjdF0b57",
        "outputId": "90fef8e4-7166-412b-d2d6-a02a782ff258"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Morpho-MNIST' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a simple VAE\n",
        "\n",
        "Using the model from\n",
        "> A. Pati and A. Lerch, Attribute-based regularization of latent spaces for variational auto-encoders. Neural Computing & Applications, 33, 4429â€“4444 (2021). https://doi.org/10.1007/s00521-020-05270-2\n",
        "\n"
      ],
      "metadata": {
        "id": "FsHMwY__5TNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "\n",
        "class MnistVAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_size = 784\n",
        "        self.z_dim = 16\n",
        "        self.inter_dim = 19\n",
        "        self.enc_conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(64, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(64, 8, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "        self.enc_lin = nn.Sequential(\n",
        "            nn.Linear(2888, 256),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.enc_mean = nn.Linear(256, self.z_dim)\n",
        "        self.enc_log_std = nn.Linear(256, self.z_dim)\n",
        "        self.dec_lin = nn.Sequential(\n",
        "            nn.Linear(self.z_dim, 256),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(256, 2888),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.dec_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(8, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ConvTranspose2d(64, 64, 4, 1),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ConvTranspose2d(64, 1, 4, 1),\n",
        "        )\n",
        "\n",
        "        self.xavier_initialization()\n",
        "\n",
        "    def xavier_initialization(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "\n",
        "    def encode(self, x):\n",
        "        hidden = self.enc_conv(x)\n",
        "        hidden = hidden.view(x.size(0), -1)\n",
        "        hidden = self.enc_lin(hidden)\n",
        "        z_mean = self.enc_mean(hidden)\n",
        "        z_log_std = self.enc_log_std(hidden)\n",
        "        z_distribution = distributions.Normal(loc=z_mean, scale=torch.exp(z_log_std))\n",
        "        return z_distribution\n",
        "\n",
        "    def decode(self, z):\n",
        "        hidden = self.dec_lin(z)\n",
        "        hidden = hidden.view(z.size(0), -1, self.inter_dim, self.inter_dim)\n",
        "        hidden = self.dec_conv(hidden)\n",
        "        return hidden\n",
        "\n",
        "    def reparametrize(self, z_dist):\n",
        "        # sample from distribution\n",
        "        z_tilde = z_dist.rsample()\n",
        "\n",
        "        # compute prior\n",
        "        prior_dist = torch.distributions.Normal(\n",
        "            loc=torch.zeros_like(z_dist.loc),\n",
        "            scale=torch.ones_like(z_dist.scale)\n",
        "        )\n",
        "        z_prior = prior_dist.sample()\n",
        "        return z_tilde, z_prior, prior_dist\n",
        "\n",
        "    def forward(self, x):\n",
        "        # compute distribution using encoder\n",
        "        z_dist = self.encode(x)\n",
        "\n",
        "        # reparametrize\n",
        "        z_tilde, z_prior, prior_dist = self.reparametrize(z_dist)\n",
        "\n",
        "        # compute output of decoding layer\n",
        "        output = self.decode(z_tilde).view(x.size())\n",
        "\n",
        "        return output, z_dist, prior_dist, z_tilde, z_prior"
      ],
      "metadata": {
        "id": "alAggbUd5VBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8hvsM1wP6lqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "mnist-lightning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}